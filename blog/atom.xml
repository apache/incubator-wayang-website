<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://wayang.apache.org/blog</id>
    <title>Apache Wayang (incubating) Blog</title>
    <updated>2024-04-17T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://wayang.apache.org/blog"/>
    <subtitle>Apache Wayang (incubating) Blog</subtitle>
    <icon>https://wayang.apache.org/img/wayang-logo.jpg</icon>
    <entry>
        <title type="html"><![CDATA[Wayang and the Federated AI]]></title>
        <id>https://wayang.apache.org/blog/wayang-federated-ai</id>
        <link href="https://wayang.apache.org/blog/wayang-federated-ai"/>
        <updated>2024-04-17T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[AI systems and applications are widely used nowadays, from assisting grammar spellings to]]></summary>
        <content type="html"><![CDATA[<p>AI systems and applications are widely used nowadays, from assisting grammar spellings to
detecting early signs of cancer cells. Building an AI requires a lot of data and training to achieve
the desired results, and federated learning is an approach to make AI training more viable.
Federated learning (or collaborative learning) is a technique that trains AI models on data
distributed across multiple serves or devices. It does so without centralizing data on a single
place or storage. It also prevents the possibility of data breaches and protects sensitive
personal data. One of the significant challenges in working with AI is the variety of tools found
in the market or the open-source community. Each tool provides results in a different form;
integrating them can be pretty challenging. Let's talk about Apache Wayang (incubating) and
how it can help to solve this problem.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="apache-wayang-in-the-federated-ai-world">Apache Wayang in the Federated AI world<a href="https://wayang.apache.org/blog/wayang-federated-ai#apache-wayang-in-the-federated-ai-world" class="hash-link" aria-label="Direct link to Apache Wayang in the Federated AI world" title="Direct link to Apache Wayang in the Federated AI world">​</a></h2>
<p>Apache Wayang (Wayang, for short), a project in an incubation phase at Apache Software
Foundation (ASF), integrates big data platforms and tools by removing the complexity of
worrying about low-level details. Interestingly, even if it was not designed for, Wayang could
also serve as a scalable platform for federated learning: the Wayang community is starting to
work on integrating federated learning capabilities. In a federated learning approach, Wayang
would allow different local models to be built and exchange its model results across other data
centers to combine them into a single enhanced model.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="a-real-world-example">A real-world example<a href="https://wayang.apache.org/blog/wayang-federated-ai#a-real-world-example" class="hash-link" aria-label="Direct link to A real-world example" title="Direct link to A real-world example">​</a></h2>
<p>Let's consider a real-world scenario. Hospitals and health organizations have increased their
investments in machine/deep learning initiatives to learn more and predict diagnostics.
However, due to legal frameworks, sharing patients' information or diagnostics is impossible,
and the solution would be to apply federated learning. To solve this problem, we could use
Wayang to help to train the models. See the diagram 1 below:</p>
<br>
<img width="75%" alt="wayang stack" src="https://wayang.apache.org/img/architecture/federated-ai-architecture-1.png">
<br>
<br>
<p>As a first step, the data scientists would send an ML task to Wayang, which will work as an
abstraction layer to connect to different data processing platforms, sparing the time to build
integration code for each. Then, the data platforms process and generate the results that will
be sent back to Wayang. Wayang aggregates the results into one "global result" and sends it
back to the requestor as a next step.</p>
<br>
<img width="75%" alt="wayang stack" src="https://wayang.apache.org/img/architecture/federated-ai-architecture-2.png">
<br>
<br>
<p>The process repeats until the desired results are achieved.
Although it is very much like a Federated learning pipeline, Wayang removes a considerable
layer of complexity from the developers by integrating with diverse types of data platforms. It
also brings fast development and reduces the need for a deep understanding of data
infrastructure or integrations. Developers can focus on the logic and how to execute tasks
instead of details about data processors.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="follow-wayang">Follow Wayang<a href="https://wayang.apache.org/blog/wayang-federated-ai#follow-wayang" class="hash-link" aria-label="Direct link to Follow Wayang" title="Direct link to Follow Wayang">​</a></h3>
<p>Apache Wayang is in an incubation phase and has a potential roadmap of implementations
coming soon (including the federated learning aspect as well as an SQL interface and a novel
data debugging functionality). If you want to hear or join the community, consult the link
<a href="https://wayang.apache.org/community/" target="_blank" rel="noopener noreferrer">https://wayang.apache.org/community/</a> , join the mailing lists, contribute with new ideas,
write documentation, or fix bugs.</p>
<br>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="thank-you">Thank you!<a href="https://wayang.apache.org/blog/wayang-federated-ai#thank-you" class="hash-link" aria-label="Direct link to Thank you!" title="Direct link to Thank you!">​</a></h5>
<p>I (Gláucia) want to thank professor Jorge Quiané for the guidance to write this blog post.
Thanks for incentivate me to join the project and for the knowledge shared. I will always remember you.</p>]]></content>
        <author>
            <name>Gláucia Esppenchutz</name>
            <uri>https://github.com/glauesppen</uri>
        </author>
        <category label="wayang" term="wayang"/>
        <category label="federated" term="federated"/>
        <category label="ai" term="ai"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pywayang - Apache Wayang's Python API]]></title>
        <id>https://wayang.apache.org/blog/wayang-python-api</id>
        <link href="https://wayang.apache.org/blog/wayang-python-api"/>
        <updated>2024-04-09T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[In the vast landscape of data processing, efficiency and flexibility are]]></summary>
        <content type="html"><![CDATA[<p>In the vast landscape of data processing, efficiency and flexibility are
important. However, navigating through a multitude of tools and
languages often is a major inconvenience.
Apache Wayang's upcoming Python API will allow you to seamlessly
orchestrate data processing tasks without ever leaving the comfort
of Python, irrespective of the underlying framework written in Java.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="expanding-apache-wayangs-apis">Expanding Apache Wayang's APIs<a href="https://wayang.apache.org/blog/wayang-python-api#expanding-apache-wayangs-apis" class="hash-link" aria-label="Direct link to Expanding Apache Wayang's APIs" title="Direct link to Expanding Apache Wayang's APIs">​</a></h2>
<p>Apache Wayang's architecture decouples the process of planning from the
resulting execution, allowing users to specify platform agnostic plans
through the provided APIs.</p>
<br>
<img width="75%" alt="wayang stack" src="https://wayang.apache.org/img/architecture/wayang-stack.png">
<br>
<br>
<p>Python's popularity and convenience for data
processing workloads makes it an obvious candidate for a desired API.
Previous APIs, such as the Scala API <code>wayang-api-scala-java</code> benefited
from the interoperability of Java and Scala that allows to reuse objects
from other languages to provide new interfaces. Accessing JVM objects in
Python is possible through several libraries, but in doing so,
future APIs in other programming languages would need similar libraries and
implementations in order to exist. As a contrast to that, providing an
API within Apache Wayang that receives input plans from any source and
executes them within allows to create plans and submit them in any
programming language. The following figure shows the architecture of <code>pywayang</code>:</p>
<br>
<img width="75%" alt="pywayang stack" src="https://wayang.apache.org/img/architecture/pywayang.png">
<br>
<br>
<p>The Python API allows users to specify WayangPlans with UDFs in Python.
<code>pywayang</code> then serializes the UDFs and constructs the WayangPlan in
JSON format, preparing it to be sent to Apache Wayang's JSON API.
When receiving a valid JSON plan, the JSON API uses the optimizer to
construct an execution plan. However, since UDFs are defined in Python
and thus need to be executed in Python as well, an operators function needs to be
wrapped into a <code>WrappedPythonFunction</code>:</p>
<div class="language-scala codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-scala codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">val</span><span class="token plain"> mapOperator </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">new</span><span class="token plain"> MapPartitionsOperator</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">Input</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> Output</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">new</span><span class="token plain"> MapPartitionsDescriptor</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">Input</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> Output</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">new</span><span class="token plain"> WrappedPythonFunction</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">Input</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> Output</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ByteString</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">copyFromUtf8</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">udf</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    classOf</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">Input</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    classOf</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">Output</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This wrapped functional descriptor allows to handle execution of
UDFs in Python through a socket connection with the <code>pywayang</code> worker.
Input data is sourced from the platform chosen by the optimizer and Apache
Wayang handles routing the output data to the next operator.</p>
<br>
<p>A new API in any programming languages would have
to specify two things:</p>
<ul>
<li>A way to create plans that conform to a JSON format specified in the
Wayang JSON API.</li>
<li>A <code>worker</code> that handles encoding and decoding of user defined
functions (UDFs), as they need to
be executed on iterables in their respective language.
After that, the API can be added as a module in Wayang, so that
operators will be wrapped and UDFs can be executed in the desired
programming language.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="defining-wayangplans-in-python">Defining WayangPlans in Python<a href="https://wayang.apache.org/blog/wayang-python-api#defining-wayangplans-in-python" class="hash-link" aria-label="Direct link to Defining WayangPlans in Python" title="Direct link to Defining WayangPlans in Python">​</a></h2>
<p>As the "Hello World!" of data processing systems, wordcount will pose as
our primary example to display how users can interact with Apache Wayang
through the python package <code>pywayang</code>.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> pywy</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">dataquanta </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> WayangContext</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> pywy</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">platforms</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">java </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> JavaPlugin</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> pywy</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">platforms</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">spark </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> SparkPlugin</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">wordcount</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ctx </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> WayangContext</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">register</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">JavaPlugin</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> SparkPlugin</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">textfile</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"file://README.md"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">flatmap</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">lambda</span><span class="token plain"> w</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> w</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">split</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">filter</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">lambda</span><span class="token plain"> w</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> w</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">strip</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">!=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">""</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">map</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">lambda</span><span class="token plain"> w</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">w</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">lower</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">reduce_by_key</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">lambda</span><span class="token plain"> t</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> t</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">lambda</span><span class="token plain"> t1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> t2</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">t1</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token builtin">int</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">t1</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">+</span><span class="token plain"> </span><span class="token builtin">int</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">t2</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">store_textfile</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"file:///wordcount-out-python.txt"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> __name__ </span><span class="token operator" style="color:#393A34">==</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"__main__"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    wordcount</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The example displays a mode of operation that resembles the Scala
<code>PlanBuilder</code> and the <code>JavaPlanBuilder</code>. Plans are specified in a
functional way, chaining operations until a terminal operation results
in execution of the plan.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="wayang-api-json">Wayang-API-JSON<a href="https://wayang.apache.org/blog/wayang-python-api#wayang-api-json" class="hash-link" aria-label="Direct link to Wayang-API-JSON" title="Direct link to Wayang-API-JSON">​</a></h2>
<p>The <code>wayang-api-json</code> module provides an executable that starts a REST
server. This server accepts a <code>WayangPlan</code> in JSON format.
Starting the REST API as a background process can be done by executing
the following:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">mvn clean package </span><span class="token parameter variable" style="color:#36acaa">-pl</span><span class="token plain"> :wayang-assembly </span><span class="token parameter variable" style="color:#36acaa">-Pdistribution</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token builtin class-name">cd</span><span class="token plain"> wayang-assembly/target/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token function" style="color:#d73a49">tar</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-xvf</span><span class="token plain"> apache-wayang-assembly-0.7.1-SNAPSHOT-incubating-dist.tar.gz</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token builtin class-name">cd</span><span class="token plain"> wayang-0.7.1-SNAPSHOT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./bin/wayang-submit org.apache.wayang.api.json.Main </span><span class="token operator" style="color:#393A34">&amp;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="wrapping-pipelines-in-mappartition-operators">Wrapping pipelines in MapPartition operators<a href="https://wayang.apache.org/blog/wayang-python-api#wrapping-pipelines-in-mappartition-operators" class="hash-link" aria-label="Direct link to Wrapping pipelines in MapPartition operators" title="Direct link to Wrapping pipelines in MapPartition operators">​</a></h2>
<p>With this architecture, the execution of an operator comes with an
additional overhead, because the UDFs will have to be executed in
python. Python operators receive iterators through a socket and also
return their result to Wayang through that connection. To minimize the
overhead, unary operators that return unary results will be grouped in
pipelines. One pipeline of operators will be submitted to the Wayang
JSON API as a single <code>MapPartition</code> operator. This means that the UDFs
specified in this pipeline can be chained and only on call from Wayang
to the Python worker will have to be made for a given pipeline.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="coming-soon">Coming soon<a href="https://wayang.apache.org/blog/wayang-python-api#coming-soon" class="hash-link" aria-label="Direct link to Coming soon" title="Direct link to Coming soon">​</a></h2>
<p>As the Python API is currently in development and we are applying
finishing touches, this article serves as an outlook for what users can
expect to see soon.</p>
<p>Author: <a href="https://github.com/juripetersen" target="_blank" rel="noopener noreferrer">juripetersen</a></p>]]></content>
        <author>
            <name>Juri Petersen</name>
            <uri>https://github.com/juripetersen</uri>
        </author>
        <category label="wayang" term="wayang"/>
        <category label="python" term="python"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Apache Kafka meets Apache Wayang - Part 3]]></title>
        <id>https://wayang.apache.org/blog/kafka-meets-wayang-3</id>
        <link href="https://wayang.apache.org/blog/kafka-meets-wayang-3"/>
        <updated>2024-03-10T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[The third part of this article series is an activity log.]]></summary>
        <content type="html"><![CDATA[<p>The third part of this article series is an activity log.
Motivated by the learnings from last time, I stated implementing a Kafka Source component and a Kafka Sink component for the Apache Spark platform in Apache Wayang.
In our previous article we shared the results of the work on the frist Apache Kafka integration using the Java Platform.</p>
<p>Let's see how it goes this time with Apache Spark.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-goal-of-this-implementation">The goal of this implementation<a href="https://wayang.apache.org/blog/kafka-meets-wayang-3#the-goal-of-this-implementation" class="hash-link" aria-label="Direct link to The goal of this implementation" title="Direct link to The goal of this implementation">​</a></h2>
<p>We want to process data from Apache Kafka topics, which are hosted on Confluent cloud.
In our example scenario, the data is available in multiple different clusters, in different regions and owned by different organizations.</p>
<p>We assume, that the operator of our job has been granted appropriate permissions, and the topic owner already provided the configuration properties, including access coordinates and credentials.</p>
<p><img decoding="async" loading="lazy" alt="images/image-1.png" src="https://wayang.apache.org/assets/images/image-1-9cc35d5aea2b867d7e5759a96bd02334.png" width="904" height="550" class="img_ev3q"></p>
<p>This illustration has already been introduced in part one.
We focus on <strong>Job 4</strong> in the image and start to implement it.
This time we expect the processing load to be higher so that we want to utilize the scalability capabilities of Apache Spark.</p>
<p>Again, we start with a <strong>WayangContext</strong>, as shown by examples in the Wayang code repository.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">WayangContext wayangContext = new WayangContext().with(Spark.basicPlugin());</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>We simply switched the backend system towards Apache Spark by using the <em>WayangContext</em> with <em>Spark.basicPlugin()</em>.
The <strong>JavaPlanBuilder</strong> and all other logic of our example job won't be touched.</p>
<p>In order to make this working we will now implement the Mappings and the Operators for the Apache Spark platform module.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="implementation-of-input--and-output-operators">Implementation of Input- and Output Operators<a href="https://wayang.apache.org/blog/kafka-meets-wayang-3#implementation-of-input--and-output-operators" class="hash-link" aria-label="Direct link to Implementation of Input- and Output Operators" title="Direct link to Implementation of Input- and Output Operators">​</a></h2>
<p>We reuse the Kafka Source and Kafka Sink components which have been created for the JavaKafkaSource and JavaKafkaSink.
Hence we work with Wayang's Java API.</p>
<p><strong>Level 1 – Wayang execution plan with abstract operators</strong></p>
<p>Since the <em>JavaPlanBuilder</em> already exposes the function for selecting a Kafka topic as source
and the <em>DataQuantaBuilder</em> class exposes the <em>writeKafkaTopic</em> function we can move on quickly.</p>
<p>Remember, in this API layer we use the Scala programming language, but we utilize the Java classes, implemented in the layer below.</p>
<p><strong>Level 2 – Wiring between Platform Abstraction and Implementation</strong></p>
<p>As in the case with the Java Platform, in the second layer we build a bridge between the WayangContext and the PlanBuilders, which work together with DataQuanta and the DataQuantaBuilder.</p>
<p>We must provide the mapping between the abstract components and the specific implementations in this layer.</p>
<p>Therefore, the mappings package in project <strong>wayang-platforms/wayang-spark</strong> has a class <em>Mappings</em> in which
our <em>KafkaTopicSinkMapping</em> and <em>KafkaTopicSourceMapping</em> will be registered.</p>
<p>Again, these classes allow the Apache Wayang framework to use the Java implementation of the KafkaTopicSource component (and KafkaTopicSink respectively).</p>
<p>While the Wayang execution plan uses the higher abstractions, here on the “platform level” we have to link the specific implementation for the target platform.
In this case this leads to an Apache Spark job, running on a Spark cluster which is set up by the Apache Wayang framework using the logical components of the execution plan, and the Apache Spark configuration provided at runtime.</p>
<p>A mapping links an operator implementation to the abstraction used in an execution plan.
We define two new mappings for our purpose, namely KafkaTopicSourceMapping, and KafkaTopicSinkMapping, both could be reused from last round.</p>
<p>For the Spark platform we simply replace the occurences of <em>JavaPlatform</em> with <em>SparkPlatform</em>.</p>
<p>Furthermore, we create an implementation of the <em>SparkKafkaTopicSource</em> and <em>SparkKafkaTopicSink</em>.</p>
<p><strong>Layer 3 – Input/Output Connector Layer</strong></p>
<p>Let's quickly recap, how does Apache Spark interacts with Apache Kafka?</p>
<p>There is already an integration which gives us a DataSet using the Spark SQL framework.
For Spark Streaming, there is also a Kafka integration using the <em>SparkSession</em>'s <em>readStream()</em> function.
Kafka client properties are provided as key value pairs <em>k</em> and <em>v</em> by using the <em>option( k, v )</em> function.
For writing into a topic, we can use the <em>writeStream()</em> function.
But from a first look, it seems to be not the best fit.</p>
<p>Another approach is possible.
We can use simple RDDs to process data previously consumed from Apache Kafka.
This is a more low-level approach compared to using Datasets with Spark Structured Streaming,
and it typically involves using the Kafka RDD API provided by Spark.</p>
<p>This approach is less common with newer versions of Spark, as Structured Streaming provides a higher-level abstraction that simplifies stream processing.
However, we might need that approach for the integration with Apache Wayang.</p>
<p>For now, we will focus on the lower level approach and plan to consume data from Kafka using a Kafka client, and then
we parallelize the records in an RDD.</p>
<p>This allows us to reuse <em>KafkaTopicSource</em> and <em>KafkaTopicSink</em> classes we built last time.
Those were made specifically for a simple non parallel Java program, using one Consumer and one Producer.</p>
<p>The selected approach does not yet fully take advantage from Spark's parallelism at load time.
For higher loads and especially for streaming processing we would have to investigate another approache, using a <em>SparkStreamingContext</em>, but this is out of scope for now.</p>
<p>Since we can't reuse the <em>JavaKafkaTopicSource</em> and <em>JavaKafkaTopicSink</em> we rather implement <em>SparkKafkaTopicSource</em> and <em>SparkKafkaTopicSink</em> based on given <em>SparkTextFileSource</em> and <em>SparkTextFileSink</em> which both cary all needed RDD specific logic.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="summary">Summary<a href="https://wayang.apache.org/blog/kafka-meets-wayang-3#summary" class="hash-link" aria-label="Direct link to Summary" title="Direct link to Summary">​</a></h2>
<p>As expected, the integration of Apache Spark with Apache Wayang was no magic, thanks to a fluent API design and a well structured architecture of Apache Wayang.
We could easily follow the pattern we have worked out in the previous exercise.</p>
<p>But a bunch of much more interesting work will follow next.
More testing, more serialization schemes, and Kafka Schema Registry support should follow, and full parallelization as well.</p>
<p>The code has been submitted to the Apache Wayang repository.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="outlook">Outlook<a href="https://wayang.apache.org/blog/kafka-meets-wayang-3#outlook" class="hash-link" aria-label="Direct link to Outlook" title="Direct link to Outlook">​</a></h2>
<p>The next part of the article series will cover the real world example as described in image 1.
We will show how analysts and developers can use the Apache Kafka integration for Apache Wayang to solve cross organizational collaboration issues.
Therefore, we will bring all puzzles together, and show the full implementation of the multi organizational data collaboration use case.</p>]]></content>
        <author>
            <name>Mirko Kämpf</name>
            <uri>https://github.com/kamir</uri>
        </author>
        <category label="wayang" term="wayang"/>
        <category label="kafka" term="kafka"/>
        <category label="spark" term="spark"/>
        <category label="cross organization data collaboration" term="cross organization data collaboration"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Apache Wayang vs. Presto/Trino]]></title>
        <id>https://wayang.apache.org/blog/wayang-vs-trino</id>
        <link href="https://wayang.apache.org/blog/wayang-vs-trino"/>
        <updated>2024-03-08T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[We have been asked several times about the difference between Apache Wayang and Presto/Trino. In this blog post, we will clarify the main differences and how they impact various applications and use cases.]]></summary>
        <content type="html"><![CDATA[<p>We have been asked several times about the difference between Apache Wayang and Presto/Trino. In this blog post, we will clarify the main differences and how they impact various applications and use cases.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-distinctions">Key Distinctions<a href="https://wayang.apache.org/blog/wayang-vs-trino#key-distinctions" class="hash-link" aria-label="Direct link to Key Distinctions" title="Direct link to Key Distinctions">​</a></h2>
<p>Trino/Presto is a <strong>query engine</strong> for <strong>distributed SQL query processing</strong>. It is composed of a coordinator and multiple workers. The coordinator consists of a query optimizer and a scheduler, while the workers are responsible for performing the necessary query processing. Data is fetched from external systems via a Connector API, i.e., Trino/Presto supports <a href="https://trino.io/ecosystem/data-source" target="_blank" rel="noopener noreferrer">multiple data sources</a>. Notably,query processing is is conducted exclusively by Trino/Presto workers, not the external systems.</p>
<p>In contrast, Wayang is a <strong>middleware</strong> for <strong>integrating diverse data platforms</strong>, including but not limited to query engines. This means that Wayang leverages the processing capabilities of the underlying data platforms to complete a given job, with no actual query processing taking place within Wayang itself.</p>
<p>Below you can graphically see the difference between the two systems. Note that not all available data sources or data platforms are illustrated for simplicity reasons.</p>
<p>Below you can see how Wayang integrates data platforms and utilizes them for any data processing required.</p>
<br>
<img width="90%" alt="Wayang" src="https://wayang.apache.org/img/blog/wayang-architecture.png" title="Wayang">
<br>
<br>
<p>Below you can see how Trino unifies different data sources and then performs data processing in a distributed manner.</p>
<br>
<img width="90%" alt="Trino" src="https://wayang.apache.org/img/blog/trino-architecture.png" title="Trino">
<br>
<p>I hope this makes it clear now. <br>
In fact, Trino can be easily plugged to Wayang as a platform and be seamlessly integrated with other data platforms, as shown below.</p>
<img width="75%" alt="Trino" src="https://wayang.apache.org/img/blog/wayang-with-trino.png">
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-are-the-advantages-of-using-wayang">What are the advantages of using Wayang?<a href="https://wayang.apache.org/blog/wayang-vs-trino#what-are-the-advantages-of-using-wayang" class="hash-link" aria-label="Direct link to What are the advantages of using Wayang?" title="Direct link to What are the advantages of using Wayang?">​</a></h2>
<p>Wayang brings several benefits thanks to its integration layer:</p>
<ul>
<li>
<p>Seamless integration of SQL query engines with ML and other data analysis systems within a single job, eliminating the need to materialize intermediate results.</p>
</li>
<li>
<p>Users are freed from the task of specifying the query engines for an application if they desire. By submitting their Wayang job, the cross-platform optimizer can automatically determine the best data platform to use for improved performance or cost savings.</p>
</li>
<li>
<p>Wayang facilitates cross-platform data processing by utilizing multiple data platforms to execute a query for a single job, optimizing performance and cost efficiency.</p>
</li>
<li>
<p>Data does not have to be transferred outside their original location.</p>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="https://wayang.apache.org/blog/wayang-vs-trino#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2>
<p>Trino is a distributed SQL query engine which performs all the query processing of an input SQL query in a distributed manner. Wayang, on the other hand, is a data platform integrator which can automatically determine which data platform(s) is best suited for an application.</p>
<p>Author: <a href="https://github.com/zkaoudi" target="_blank" rel="noopener noreferrer">zkaoudi</a></p>]]></content>
        <author>
            <name>Zoi Kaoudi</name>
            <uri>https://github.com/zkaoudi</uri>
        </author>
        <category label="wayang" term="wayang"/>
        <category label="presto" term="presto"/>
        <category label="trino" term="trino"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Apache Kafka meets Apache Wayang - Part 2]]></title>
        <id>https://wayang.apache.org/blog/kafka-meets-wayang-2</id>
        <link href="https://wayang.apache.org/blog/kafka-meets-wayang-2"/>
        <updated>2024-03-06T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[In the second part of the article series we describe the implementation of the Kafka Source and Kafka Sink component for Apache Wayang.]]></summary>
        <content type="html"><![CDATA[<p>In the second part of the article series we describe the implementation of the Kafka Source and Kafka Sink component for Apache Wayang.
We look into the “Read- and Write-Path” for our data items, called <em>DataQuanta</em>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="apache-wayangs-read--write-path-for-kafka-topics">Apache Wayang’s Read &amp; Write Path for Kafka topics<a href="https://wayang.apache.org/blog/kafka-meets-wayang-2#apache-wayangs-read--write-path-for-kafka-topics" class="hash-link" aria-label="Direct link to Apache Wayang’s Read &amp; Write Path for Kafka topics" title="Direct link to Apache Wayang’s Read &amp; Write Path for Kafka topics">​</a></h2>
<p>To describe the read and write paths for data in the context of the created Apache Wayang code snippet, the primary classes and interfaces we need to understand are as follows:</p>
<p><strong>WayangContext:</strong> This class is essential for initializing the Wayang processing environment.
It allows you to configure the execution environment and register plugins that define which platforms Wayang can use for data processing tasks, such as <em>Java.basicPlugin()</em> for local Java execution.</p>
<p><strong>JavaPlanBuilder:</strong> This class is used to build and define the data processing pipeline (or plan) in Wayang.
It provides a fluent API to specify the operations to be performed on the data, from reading the input to processing it and writing the output.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="read-path">Read Path<a href="https://wayang.apache.org/blog/kafka-meets-wayang-2#read-path" class="hash-link" aria-label="Direct link to Read Path" title="Direct link to Read Path">​</a></h3>
<p>The read path describes how data is ingested from a source into the Wayang processing pipeline:</p>
<p><em>Reading from Kafka Topic:</em> The method <em>readKafkaTopic(topicName)</em> is used to ingest data from a specified Kafka topic.
This is the starting point of the data processing pipeline, where topicName represents the name of the Kafka topic from which data is read.</p>
<p><em>Data Tokenization and Preparation:</em> Once the data is read from Kafka, it undergoes several transformations such as Splitting, Filtering, and Mapping.
What follows are the procedures known as Reducing, Grouping, Co-Grouping, and Counting.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="write-path">Write Path<a href="https://wayang.apache.org/blog/kafka-meets-wayang-2#write-path" class="hash-link" aria-label="Direct link to Write Path" title="Direct link to Write Path">​</a></h3>
<p><em>Writing to Kafka Topic:</em> The final step in the pipeline involves writing the processed data back to a Kafka topic using <em>.writeKafkaTopic(...)</em>.
This method takes parameters that specify the target Kafka topic, a serialization function to format the data as strings, and additional configuration for load profile estimation, which optimizes the writing process.</p>
<p>This read-write path provides a comprehensive flow of data from ingestion from Kafka, through various processing steps, and finally back to Kafka, showcasing a full cycle of data processing within Apache Wayang's abstracted environment and is implemented in our example program shown in <em>listing 1</em>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="implementation-of-input--and-output-operators">Implementation of Input- and Output Operators<a href="https://wayang.apache.org/blog/kafka-meets-wayang-2#implementation-of-input--and-output-operators" class="hash-link" aria-label="Direct link to Implementation of Input- and Output Operators" title="Direct link to Implementation of Input- and Output Operators">​</a></h2>
<p>The next section shows how a new pair of operators can be implemented to extend Apache Wayang’s capabilities on the input and output side.
We created the Kafka Source and Kafka Sink components so that our cross organizational data collaboration scenario can be implemented using data streaming infrastructure.</p>
<p><strong>Level 1 – Wayang execution plan with abstract operators</strong></p>
<p>The implementation of our Kafka Source and Kafka Sink components for Apache Wayang requires new methods and classes on three layers.
First of all in the API package.
Here we use the JavaPlanBuilder to expose the function for selecting a Kafka topic as the source to be used by client.<br>
<!-- -->The class <em>JavaPlanBuilder</em> in package <em>org.apache.wayang.api</em> in the project <em>wayang-api/wayang-api-scala-java</em> exposes our new functionality to our external client.
An instance of the JavaPlanBuilder is used to define the data processing pipeline.
We use its <em>readKafkaTopic()</em> which specifies the source Kafka topic to read from, and for the write path we use the <em>writeKafkaTopic()</em> method.
Both Methods do only trigger activities in the background.</p>
<p>For the output side, we use the <em>DataQuantaBuilder</em> class, which offers an implementation of the writeKafkaTopic function.
This function is designed to send processed data, referred to as DataQuanta, to a specified Kafka topic.
Essentially, it marks the final step in a data processing sequence constructed using the Apache Wayang framework.</p>
<p>In the DataQuanta class we implemented the methods writeKafkaTopic and writeKafkaTopicJava which use the KafkaTopicSink class.
In this API layer we use the Scala programming language, but we utilize the Java classes, implemented in the layer below.</p>
<p><strong>Level 2 – Wiring between Platform Abstraction and Implementation</strong></p>
<p>The second layer builds the bridge between the WayangContext and PlanBuilders which work together with DataQuanta and the DataQuantaBuilder.</p>
<p>Also, the mapping between the abstract components and the specific implementations are defined in this layer.</p>
<p>Therefore, the mappings package has a class <em>Mappings</em> in which all relevant input and output operators are listed.
We use it to register the KafkaSourceMapping and a KafkaSinkMapping for the particular platform, Java in our case.
These classes allow the Apache Wayang framework to use the Java implementation of the KafkaTopicSource component (and KafkaTopicSink respectively).
While the Wayang execution plan uses the higher abstractions, here on the “platform level” we have to link the specific implementation for the target platform.
In our case this leads to a Java program running on a JVM which is set up by the Apache Wayang framework using the logical components of the execution plan.</p>
<p>Those mappings link the real implementation of our operators the ones used in an execution plan.
The JavaKafkaTopicSource and the JavaKafkaTopicSink extend the KafkaTopicSource and KafkaTopicSink so that the lower level implementation of those classes become available within Wayang’s Java Platform context.</p>
<p>In this layer, the KafkaConsumer class and the KafkaProducer class are used, but both are configured and instantiated in the next layer underneath.
All this is done in the project <em>wayang-plarforms/wayang-java</em>.</p>
<p><strong>Layer 3 – Input/Output Connector Layer</strong></p>
<p>The <em>KafkaTopicSource</em> and <em>KafkaTopicSink</em> classes build the third layer of our implementation.
Both are implemented in Java programming language.
In this layer, the real Kafka-Client logic is defined.
Details about consumer and producers, client configuration, and schema handling have to be handled here.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="summary">Summary<a href="https://wayang.apache.org/blog/kafka-meets-wayang-2#summary" class="hash-link" aria-label="Direct link to Summary" title="Direct link to Summary">​</a></h2>
<p>Both classes in the third layer implement the Kafka client logic which is needed by the Wayang-execution plan when external data flows should be established.
The layer above handles the mapping of the components at startup time.
All this wiring is needed to keep Wayang open and flexible so that multiple external systems can be used in a variety of combinations and using multiple target platforms in combinations.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="outlook">Outlook<a href="https://wayang.apache.org/blog/kafka-meets-wayang-2#outlook" class="hash-link" aria-label="Direct link to Outlook" title="Direct link to Outlook">​</a></h2>
<p>The next part of the article series will cover the creation of an Kafka Source and Sink component for the Apache Spark platform, which allows our use case to scale.
Finally, in part four we bring all puzzles together, and show the full implementation of the multi organizational data collaboration use case.</p>]]></content>
        <author>
            <name>Mirko Kämpf</name>
            <uri>https://github.com/kamir</uri>
        </author>
        <category label="wayang" term="wayang"/>
        <category label="kafka" term="kafka"/>
        <category label="cross organization data collaboration" term="cross organization data collaboration"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Apache Kafka meets Apache Wayang - Part 1]]></title>
        <id>https://wayang.apache.org/blog/kafka-meets-wayang-1</id>
        <link href="https://wayang.apache.org/blog/kafka-meets-wayang-1"/>
        <updated>2024-03-05T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Intro]]></summary>
        <content type="html"><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="intro">Intro<a href="https://wayang.apache.org/blog/kafka-meets-wayang-1#intro" class="hash-link" aria-label="Direct link to Intro" title="Direct link to Intro">​</a></h2>
<p>This article is the first of a four part series about federated data analysis using Apache Wayang.
The first article starts with an introduction of a typical data colaboration scenario which will emerge in our digital future.</p>
<p>In part two and three we will share a summary of our Apache Kafka client implementation for Apache Wayang.
We started with the Java Platform (part 2) and the Apache Spark implementation follows (W.I.P.) in part three.</p>
<p>The use case behind this work is an imaginary data collaboration scenario.
We see this example and the demand for a solution already in many places.<br>
<!-- -->For us this is motivation enough to propose a solution.
This would also allow us to do more local data processing, and businesses can stop moving data around the world, but rather care about data locality while they expose and share specific information to others by using data federation.
This reduces complexity of data management and cost dramatically.</p>
<p>For this purpose, we illustrate a cross organizational data sharing scenario from the finance sector soon.
This analysis pattern will also be relevant in the context of data analysis along supply chains, another typical example where data from many stakeholder together is needed but never managed in one place, for good reasons.</p>
<p>Data federation can help us to unlock the hidden value of all those isolated data lakes.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="a-cross-organizational-data-sharing-scenario">A cross organizational data sharing scenario<a href="https://wayang.apache.org/blog/kafka-meets-wayang-1#a-cross-organizational-data-sharing-scenario" class="hash-link" aria-label="Direct link to A cross organizational data sharing scenario" title="Direct link to A cross organizational data sharing scenario">​</a></h2>
<p>Our goal is the implementation of a cross organization decentralized data processing scenario, in which protected local data should be processed in combination with public data from public sources in a collaborative manner.
Instead of copying all data into a central data lake or a central data platform we decided to use federated analytics.
Apache Wayang is the tool we work with.
In our case, the public data is hosted on publicly available websites or data pods.
A client can use the HTTP(S) protocol to read the data which is given in a well defined format.
For simplicity we decided to use CSV format.
When we look into the data of each participant we have a different perspective.</p>
<p>Our processing procedure should calculate a particular metric on the <em>local data</em> of each participant.
An example of such a metric is the average spending of all users on a particular product category per month.
This can vary from partner to partner, hence, we want to be able to calculate a peer-group comparison so that each partner can see its own metric compared with a global average calculated from contributions by all partners.
Such a process requires global averaging and local averaging.
And due to governance constraints, we can’t bring all raw data together in one place.</p>
<p>Instead, we want to use Apache Wayang for this purpose.
We simplify the procedure and split it into two phases.
Phase one is the process, which allows each participant to calculate the local metrics.
This requires only local data. The second phase requires data from all collaborating partners.
The monthly sum and counter values per partner and category are needed in one place by all other parties.
Hence, the algorithm of the first phase stores the local results locally, and the contributions to the global results in an externally accessible Kafka topic.
We assume this is done by each of the partners.</p>
<p>Now we have a scenario, in which an Apache Wayang process must be able to read data from multiple Apache Kafka topics from multiple Apache Kafka clusters but finally writes into a single Kafka topic, which then can be accessed by all the participating clients.</p>
<p><img decoding="async" loading="lazy" alt="images/image-1.png" src="https://wayang.apache.org/assets/images/image-1-9cc35d5aea2b867d7e5759a96bd02334.png" width="904" height="550" class="img_ev3q"></p>
<p>The illustration shows the data flows in such a scenario.
Jobs with red border are executed by the participants in isolation within their own data processing environments.
But they share some of the data, using publicly accessible Kafka topics, marked by A. Job 4 is the Apache Wayang job in our focus: here we intent to read data from 3 different source systems, and write results into a fourth system (marked as B), which can be accesses by all participants again.</p>
<p>With this in mind we want to implement an Apache Wayang application which implements the illustrated <em>Job 4</em>.
Since as of today, there is now <em>KafkaSource</em> and <em>KafkaSink</em> available in Apache Wayang, an implementation of both will be our first step.
Our assumption is, that in the beginning, there won’t be much data.</p>
<p>Apache Spark is not required to cope with the load, but we expect, that in the future, a single Java application would not be able to handle our workload.
Hence, we want to utilize the Apache Wayang abstraction over multiple processing platforms, starting with Java.
Later, we want to switch to Apache Spark.</p>]]></content>
        <author>
            <name>Mirko Kämpf</name>
            <uri>https://github.com/kamir</uri>
        </author>
        <category label="wayang" term="wayang"/>
        <category label="kafka" term="kafka"/>
        <category label="cross organization data collaboration" term="cross organization data collaboration"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Website updated]]></title>
        <id>https://wayang.apache.org/blog/website_update</id>
        <link href="https://wayang.apache.org/blog/website_update"/>
        <updated>2024-01-25T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[We're updated our website and use now Docusaurus.]]></summary>
        <content type="html"><![CDATA[<p>We're updated our website and use now Docusaurus.</p>
<p>Author: <a href="https://github.com/2pk03" target="_blank" rel="noopener noreferrer">2pk03</a></p>
<p>We switched to a new CMS. That's all.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="cheatsheet">Cheatsheet<a href="https://wayang.apache.org/blog/website_update#cheatsheet" class="hash-link" aria-label="Direct link to Cheatsheet" title="Direct link to Cheatsheet">​</a></h2>
<p>List:</p>
<ul>
<li>Line one<!-- -->
<ul>
<li>Line one.one</li>
<li>Line one.two</li>
</ul>
</li>
<li>Line two<!-- -->
<ul>
<li>Line two.one</li>
<li>Line two.two</li>
</ul>
</li>
<li>Line three<!-- -->
<ul>
<li>...</li>
<li>...</li>
</ul>
</li>
</ul>
<p>Another style for a list:</p>
<ul>
<li>Line one</li>
<li>Line two</li>
<li>Line three</li>
</ul>]]></content>
        <author>
            <name>Alexander Alten</name>
            <uri>https://github.com/2pk03</uri>
        </author>
        <category label="wayang" term="wayang"/>
    </entry>
</feed>