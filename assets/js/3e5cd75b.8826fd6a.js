"use strict";(self.webpackChunkwayang_website=self.webpackChunkwayang_website||[]).push([[8045],{6722:(a,e,t)=>{t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>p,frontMatter:()=>i,metadata:()=>s,toc:()=>c});var n=t(5893),o=t(1151);const i={slug:"kafka-meets-wayang-1",title:"Apache Kafka meets Wayang - Part 1",authors:"kamir",tags:["wayang","kafka","cross organization data collaboration"]},r="Apache Wayang meets Apache Kafka - Part 1",s={permalink:"/blog/kafka-meets-wayang-1",source:"@site/blog/2024-03-05-kafka-meets-wayang-1.md",title:"Apache Kafka meets Wayang - Part 1",description:"Intro",date:"2024-03-05T00:00:00.000Z",formattedDate:"March 5, 2024",tags:[{label:"wayang",permalink:"/blog/tags/wayang"},{label:"kafka",permalink:"/blog/tags/kafka"},{label:"cross organization data collaboration",permalink:"/blog/tags/cross-organization-data-collaboration"}],readingTime:3.925,hasTruncateMarker:!1,authors:[{name:"Mirko K\xe4mpf",title:"(P)PMC Apache Wayang",url:"https://github.com/kamir",imageURL:"https://avatars.githubusercontent.com/u/1241122?v=4",key:"kamir"}],frontMatter:{slug:"kafka-meets-wayang-1",title:"Apache Kafka meets Wayang - Part 1",authors:"kamir",tags:["wayang","kafka","cross organization data collaboration"]},unlisted:!1,prevItem:{title:"Apache Kafka meets Wayang - Part 2",permalink:"/blog/kafka-meets-wayang-2"},nextItem:{title:"Website updated",permalink:"/blog/website_update"}},l={authorsImageUrls:[void 0]},c=[{value:"Intro",id:"intro",level:2},{value:"A cross organizational data sharing scenario",id:"a-cross-organizational-data-sharing-scenario",level:2}];function h(a){const e={em:"em",h2:"h2",img:"img",p:"p",...(0,o.a)(),...a.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.h2,{id:"intro",children:"Intro"}),"\n",(0,n.jsx)(e.p,{children:"This article is the first of a four part series about federated data analysis using Apache Wayang.\nThe first article starts with an introduction of a typical data colaboration scenario which will emerge in our digital future."}),"\n",(0,n.jsx)(e.p,{children:"In part two and three we will share a summary of our Apache Kafka client implementation for Apache Wayang.\nWe started with the Java Platform (part 2) and the Apache Spark implementation follows (W.I.P.) in part three."}),"\n",(0,n.jsx)(e.p,{children:"The use case behind this work is an imaginary data collaboration scenario.\nWe see this example and the demand for a solution already in many places.\nFor us this is motivation enough to propose a solution.\nThis would also allow us to do more local data processing, and businesses can stop moving data around the world, but rather care about data locality while they expose and share specific information to others by using data federation.\nThis reduces complexity of data management and cost dramatically."}),"\n",(0,n.jsx)(e.p,{children:"For this purpose, we illustrate a cross organizational data sharing scenario from the finance sector soon.\nThis analysis pattern will also be relevant in the context of data analysis along supply chains, another typical example where data from many stakeholder together is needed but never managed in one place, for good reasons."}),"\n",(0,n.jsx)(e.p,{children:"Data federation can help us to unlock the hidden value of all those isolated data lakes."}),"\n",(0,n.jsx)(e.h2,{id:"a-cross-organizational-data-sharing-scenario",children:"A cross organizational data sharing scenario"}),"\n",(0,n.jsx)(e.p,{children:"Our goal is the implementation of a cross organization decentralized data processing scenario, in which protected local data should be processed in combination with public data from public sources in a collaborative manner.\nInstead of copying all data into a central data lake or a central data platform we decided to use federated analytics.\nApache Wayang is the tool we work with.\nIn our case, the public data is hosted on publicly available websites or data pods.\nA client can use the HTTP(S) protocol to read the data which is given in a well defined format.\nFor simplicity we decided to use CSV format.\nWhen we look into the data of each participant we have a different perspective."}),"\n",(0,n.jsxs)(e.p,{children:["Our processing procedure should calculate a particular metric on the ",(0,n.jsx)(e.em,{children:"local data"})," of each participant.\nAn example of such a metric is the average spending of all users on a particular product category per month.\nThis can vary from partner to partner, hence, we want to be able to calculate a peer-group comparison so that each partner can see its own metric compared with a global average calculated from contributions by all partners.\nSuch a process requires global averaging and local averaging.\nAnd due to governance constraints, we can\u2019t bring all raw data together in one place."]}),"\n",(0,n.jsx)(e.p,{children:"Instead, we want to use Apache Wayang for this purpose.\nWe simplify the procedure and split it into two phases.\nPhase one is the process, which allows each participant to calculate the local metrics.\nThis requires only local data. The second phase requires data from all collaborating partners.\nThe monthly sum and counter values per partner and category are needed in one place by all other parties.\nHence, the algorithm of the first phase stores the local results locally, and the contributions to the global results in an externally accessible Kafka topic.\nWe assume this is done by each of the partners."}),"\n",(0,n.jsx)(e.p,{children:"Now we have a scenario, in which an Apache Wayang process must be able to read data from multiple Apache Kafka topics from multiple Apache Kafka clusters but finally writes into a single Kafka topic, which then can be accessed by all the participating clients."}),"\n",(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{alt:"images/image-1.png",src:t(655).Z+"",width:"904",height:"550"})}),"\n",(0,n.jsx)(e.p,{children:"The illustration shows the data flows in such a scenario.\nJobs with red border are executed by the participants in isolation within their own data processing environments.\nBut they share some of the data, using publicly accessible Kafka topics, marked by A. Job 4 is the Apache Wayang job in our focus: here we intent to read data from 3 different source systems, and write results into a fourth system (marked as B), which can be accesses by all participants again."}),"\n",(0,n.jsxs)(e.p,{children:["With this in mind we want to implement an Apache Wayang application which implements the illustrated ",(0,n.jsx)(e.em,{children:"Job 4"}),".\nSince as of today, there is now ",(0,n.jsx)(e.em,{children:"KafkaSource"})," and ",(0,n.jsx)(e.em,{children:"KafkaSink"})," available in Apache Wayang, an implementation of both will be our first step.\nOur assumption is, that in the beginning, there won\u2019t be much data."]}),"\n",(0,n.jsx)(e.p,{children:"Apache Spark is not required to cope with the load, but we expect, that in the future, a single Java application would not be able to handle our workload.\nHence, we want to utilize the Apache Wayang abstraction over multiple processing platforms, starting with Java.\nLater, we want to switch to Apache Spark."})]})}function p(a={}){const{wrapper:e}={...(0,o.a)(),...a.components};return e?(0,n.jsx)(e,{...a,children:(0,n.jsx)(h,{...a})}):h(a)}},655:(a,e,t)=>{t.d(e,{Z:()=>n});const n=t.p+"assets/images/image-1-9cc35d5aea2b867d7e5759a96bd02334.png"},1151:(a,e,t)=>{t.d(e,{Z:()=>s,a:()=>r});var n=t(7294);const o={},i=n.createContext(o);function r(a){const e=n.useContext(i);return n.useMemo((function(){return"function"==typeof a?a(e):{...e,...a}}),[e,a])}function s(a){let e;return e=a.disableParentContext?"function"==typeof a.components?a.components(o):a.components||o:r(a.components),n.createElement(i.Provider,{value:e},a.children)}}}]);