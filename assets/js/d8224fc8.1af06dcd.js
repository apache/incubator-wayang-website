"use strict";(self.webpackChunkwayang_website=self.webpackChunkwayang_website||[]).push([[196],{1572:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>p,frontMatter:()=>o,metadata:()=>s,toc:()=>c});var i=a(5893),t=a(1151);const o={title:"Getting started",sidebar_position:2,id:"getting-started"},r=void 0,s={id:"guide/getting-started",title:"Getting started",description:"\x3c!--",source:"@site/docs/guide/getting-started.md",sourceDirName:"guide",slug:"/guide/getting-started",permalink:"/docs/guide/getting-started",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:2,frontMatter:{title:"Getting started",sidebar_position:2,id:"getting-started"},sidebar:"guideSidebar",previous:{title:"How to build Wayang",permalink:"/docs/guide/installation"},next:{title:"Scalable Machine Learning",permalink:"/docs/guide/ml4all"}},l={},c=[{value:"Requirements",id:"requirements",level:2},{value:"Get Wayang",id:"get-wayang",level:3},{value:"Configure Wayang",id:"configure-wayang",level:3},{value:"Cost Functions",id:"cost-functions",level:2},{value:"Examples",id:"examples",level:2},{value:"WordCount",id:"wordcount",level:3},{value:"Java API",id:"java-api",level:4},{value:"Scala API",id:"scala-api",level:4},{value:"k-means",id:"k-means",level:3},{value:"Scala API",id:"scala-api-1",level:4}];function d(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,t.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h2,{id:"requirements",children:"Requirements"}),"\n",(0,i.jsx)(n.p,{children:"Apache Wayang (incubating) is built upon the foundations of Java 11 and Scala 2.12, providing a robust and versatile platform for data processing applications. If you intend to build Wayang from source, you will also need to have Apache Maven, the popular build automation tool, installed on your system. Additionally, be mindful that some of the processing platforms supported by Wayang may have their own specific installation requirements."}),"\n",(0,i.jsx)(n.h3,{id:"get-wayang",children:"Get Wayang"}),"\n",(0,i.jsx)(n.p,{children:"Apache Wayang is readily available through Maven Central, facilitating seamless integration into your development workflow. For instance, to utilize Wayang in your Maven-based project, simply add the following dependency to your project's POM file:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:"<dependency>\n  <groupId>org.apache.wayang</groupId>\n  <artifactId>wayang-***</artifactId>\n  <version>0.7.1</version>\n</dependency>\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Note the ",(0,i.jsx)(n.code,{children:"***"}),": Wayang ships with multiple modules that can be included in your app, depending on how you want to use it:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang-core"}),": provides core data structures and the optimizer (required)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang-basic"}),": provides common operators and data types for your apps (recommended)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang-api"}),": provides an easy-to-use Scala and Java API to assemble Wayang plans (recommended)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang-java"}),", ",(0,i.jsx)(n.code,{children:"wayang-spark"}),", ",(0,i.jsx)(n.code,{children:"wayang-graphchi"}),", ",(0,i.jsx)(n.code,{children:"wayang-sqlite3"}),", ",(0,i.jsx)(n.code,{children:"wayang-postgres"}),": adapters for the various supported processing platforms"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang-profiler"}),": provides functionality to learn operator and UDF cost functions from historical execution data"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["For the sake of version flexibility, you still have to include your Hadoop (",(0,i.jsx)(n.code,{children:"hadoop-hdfs"})," and ",(0,i.jsx)(n.code,{children:"hadoop-common"}),") and Spark (",(0,i.jsx)(n.code,{children:"spark-core"})," and ",(0,i.jsx)(n.code,{children:"spark-graphx"}),") version of choice."]}),"\n",(0,i.jsx)(n.p,{children:"In addition, you can obtain the most recent snapshot version of Wayang via Sonatype's snapshot repository. Just included"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:"<repositories>\n  <repository>\n    <id>sonatype-snapshots</id>\n    <name>Sonatype Snapshot Repository</name>\n    <url>https://oss.sonatype.org/content/repositories/snapshots</url>\n  </repository>\n<repositories>\n"})}),"\n",(0,i.jsx)(n.p,{children:"If you need to rebuild Wayang, e.g., to use a different Scala version, you can simply do so via Maven:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Adapt the version variables (e.g., ",(0,i.jsx)(n.code,{children:"spark.version"}),") in the main ",(0,i.jsx)(n.code,{children:"pom.xml"})," file."]}),"\n",(0,i.jsxs)(n.li,{children:["Build Wayang with the adapted versions.","\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"$ mvn clean install\n"})}),"\n","Note the ",(0,i.jsx)(n.code,{children:"standalone"})," profile to fix Hadoop and Spark versions, so that Wayang apps do not explicitly need to declare the corresponding dependencies.\nAlso, note the ",(0,i.jsx)(n.code,{children:"distro"})," profile, which assembles a binary Wayang distribution.\nTo activate these profiles, you need to specify them when running maven, i.e.,","\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"mvn clean install -P<profile name>\n"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"configure-wayang",children:"Configure Wayang"}),"\n",(0,i.jsx)(n.p,{children:"To enable Apache Wayang's smooth operation, you need to equip it with details about your processing platforms' capabilities and how to interact with them. A default configuration is available for initial testing, but creating a properties file is generally preferable for fine-tuning the configuration to suit your specific requirements. To harness this personalized configuration effortlessly, launch your application via"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"$ java -Dwayang.configuration=url://to/my/wayang.properties ...\n"})}),"\n",(0,i.jsx)(n.p,{children:"Essential configuration settings:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["General settings","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang.core.log.enabled (= true)"}),": whether to log execution statistics to allow learning better cardinality and cost estimators for the optimizer"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang.core.log.executions (= ~/.wayang/executions.json)"})," where to log execution times of operator groups"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang.core.log.cardinalities (= ~/.wayang/cardinalities.json)"})," where to log cardinality measurements"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang.core.optimizer.instrumentation (= org.apache.wayang.core.profiling.OutboundInstrumentationStrategy)"}),": where to measure cardinalities in Wayang plans; other options are ",(0,i.jsx)(n.code,{children:"org.apache.wayang.core.profiling.NoInstrumentationStrategy"})," and ",(0,i.jsx)(n.code,{children:"org.apache.wayang.core.profiling.FullInstrumentationStrategy"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang.core.optimizer.reoptimize (= false)"}),": whether to progressively optimize Wayang plans"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang.basic.tempdir (= file:///tmp)"}),": where to store temporary files, in particular for inter-platform communication"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Java Streams","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang.java.cpu.mhz (= 2700)"}),": clock frequency of processor the JVM runs on in MHz"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang.java.hdfs.ms-per-mb (= 2.7)"}),": average throughput from HDFS to JVM in ms/MB"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Apache Spark","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"spark.master (= local)"}),": Spark master","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["various other Spark settings are supported, e.g., ",(0,i.jsx)(n.code,{children:"spark.executor.memory"}),", ",(0,i.jsx)(n.code,{children:"spark.serializer"}),", ..."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang.spark.cpu.mhz (= 2700)"}),": clock frequency of processor the Spark workers run on in MHz"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang.spark.hdfs.ms-per-mb (= 2.7)"}),": average throughput from HDFS to the Spark workers in ms/MB"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang.spark.network.ms-per-mb (= 8.6)"}),": average network throughput of the Spark workers in ms/MB"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang.spark.init.ms (= 4500)"}),": time it takes Spark to initialize in ms"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["GraphChi","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang.graphchi.cpu.mhz (= 2700)"}),": clock frequency of processor GraphChi runs on in MHz"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang.graphchi.cpu.cores (= 2)"}),": number of cores GraphChi runs on"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang.graphchi.hdfs.ms-per-mb (= 2.7)"}),": average throughput from HDFS to GraphChi in ms/MB"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["SQLite","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang.sqlite3.jdbc.url"}),": JDBC URL to use SQLite"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang.sqlite3.jdbc.user"}),": optional user name"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang.sqlite3.jdbc.password"}),": optional password"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang.sqlite3.cpu.mhz (= 2700)"}),": clock frequency of processor SQLite runs on in MHz"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang.sqlite3.cpu.cores (= 2)"}),": number of cores SQLite runs on"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["PostgreSQL","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang.postgres.jdbc.url"}),": JDBC URL to use PostgreSQL"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang.postgres.jdbc.user"}),": optional user name"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang.postgres.jdbc.password"}),": optional password"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang.postgres.cpu.mhz (= 2700)"}),": clock frequency of processor PostgreSQL runs on in MHz"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"wayang.postgres.cpu.cores (= 2)"}),": number of cores PostgreSQL runs on"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["To effectively define your applications with Apache Wayang, utilize its Scala or Java API, conveniently found within the ",(0,i.jsx)(n.code,{children:"wayang-api"})," module. For clear illustrations, refer to the provided examples below."]}),"\n",(0,i.jsx)(n.h2,{id:"cost-functions",children:"Cost Functions"}),"\n",(0,i.jsx)(n.p,{children:"Wayang provides a utility to learn cost functions from historical execution data. Specifically, Wayang can learn configurations for load profile estimators (that estimate CPU load, disk load etc.) for both operators and UDFs, as long as the configuration provides a template for those estimators."}),"\n",(0,i.jsxs)(n.p,{children:["As an example, the ",(0,i.jsx)(n.code,{children:"JavaMapOperator"})," draws its load profile estimator configuration via the configuration key ",(0,i.jsx)(n.code,{children:"wayang.java.map.load"}),".\nNow, it is possible to specify a load profile estimator template in the configuration under the key ",(0,i.jsx)(n.code,{children:"<original key>.template"}),", e.g.:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'wayang.java.map.load.template = {\\\n  "in":1, "out":1,\\\n  "cpu":"?*in0"\\\n}\n'})}),"\n",(0,i.jsx)(n.p,{children:"This template encapsulates a load profile estimator that requires at minimum one input cardinality and one output cardinality. Furthermore, it simulates CPU load by assuming a direct relationship with the input cardinality. However, more complex functions are possible."}),"\n",(0,i.jsx)(n.p,{children:"In particular, you can use"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["the variables ",(0,i.jsx)(n.code,{children:"in0"}),", ",(0,i.jsx)(n.code,{children:"in1"}),", ... and ",(0,i.jsx)(n.code,{children:"out0"}),", ",(0,i.jsx)(n.code,{children:"out1"}),", ... to incorporate the input and output cardinalities, respectively;"]}),"\n",(0,i.jsxs)(n.li,{children:["operator properties, such as ",(0,i.jsx)(n.code,{children:"numIterations"})," for the ",(0,i.jsx)(n.code,{children:"PageRankOperator"})," implementations;"]}),"\n",(0,i.jsxs)(n.li,{children:["the operators ",(0,i.jsx)(n.code,{children:"+"}),", ",(0,i.jsx)(n.code,{children:"-"}),", ",(0,i.jsx)(n.code,{children:"*"}),", ",(0,i.jsx)(n.code,{children:"/"}),", ",(0,i.jsx)(n.code,{children:"%"}),", ",(0,i.jsx)(n.code,{children:"^"}),", and parantheses;"]}),"\n",(0,i.jsxs)(n.li,{children:["the functions ",(0,i.jsx)(n.code,{children:"min(x0, x1, ...))"}),", ",(0,i.jsx)(n.code,{children:"max(x0, x1, ...)"}),", ",(0,i.jsx)(n.code,{children:"abs(x)"}),", ",(0,i.jsx)(n.code,{children:"log(x, base)"}),", ",(0,i.jsx)(n.code,{children:"ln(x)"}),", ",(0,i.jsx)(n.code,{children:"ld(x)"}),";"]}),"\n",(0,i.jsxs)(n.li,{children:["and the constants ",(0,i.jsx)(n.code,{children:"e"})," and ",(0,i.jsx)(n.code,{children:"pi"}),"."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"While Apache Wayang provides templates for all execution operators, you will need to explicitly define your user-defined functions (UDFs) by specifying their cost functions, which are based on configuration parameters. This involves creating an initial specification and template for each UDF.\nAs soon as execution data has been collected, you can initiate:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"java ... org.apache.wayang.profiler.ga.GeneticOptimizerApp [configuration URL [execution log]]\n"})}),"\n",(0,i.jsxs)(n.p,{children:["This tool will attempt to determine suitable values for the question marks (",(0,i.jsx)(n.code,{children:"?"}),") within the load profile estimator templates, aligning them with the collected execution data and pre-defined configuration entries for the load profile estimators. These optimized values can then be directly incorporated into your configuration."]}),"\n",(0,i.jsx)(n.h2,{id:"examples",children:"Examples"}),"\n",(0,i.jsxs)(n.p,{children:["For some executable examples, have a look at ",(0,i.jsx)(n.a,{href:"https://github.com/sekruse/rheem-examples",children:"this repository"}),"."]}),"\n",(0,i.jsx)(n.h3,{id:"wordcount",children:"WordCount"}),"\n",(0,i.jsx)(n.h4,{id:"java-api",children:"Java API"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:'import org.apache.wayang.api.JavaPlanBuilder;\nimport org.apache.wayang.basic.data.Tuple2;\nimport org.apache.wayang.core.api.Configuration;\nimport org.apache.wayang.core.api.WayangContext;\nimport org.apache.wayang.core.optimizer.cardinality.DefaultCardinalityEstimator;\nimport org.apache.wayang.java.Java;\nimport org.apache.wayang.spark.Spark;\nimport java.util.Collection;\nimport java.util.Arrays;\n\npublic class WordcountJava {\n\n    public static void main(String[] args){\n\n        // Settings\n        String inputUrl = "file:/tmp.txt";\n\n        // Get a plan builder.\n        WayangContext wayangContext = new WayangContext(new Configuration())\n                .withPlugin(Java.basicPlugin())\n                .withPlugin(Spark.basicPlugin());\n        JavaPlanBuilder planBuilder = new JavaPlanBuilder(wayangContext)\n                .withJobName(String.format("WordCount (%s)", inputUrl))\n                .withUdfJarOf(WordcountJava.class);\n\n        // Start building the WayangPlan.\n        Collection<Tuple2<String, Integer>> wordcounts = planBuilder\n                // Read the text file.\n                .readTextFile(inputUrl).withName("Load file")\n\n                // Split each line by non-word characters.\n                .flatMap(line -> Arrays.asList(line.split("\\\\W+")))\n                .withSelectivity(10, 100, 0.9)\n                .withName("Split words")\n\n                // Filter empty tokens.\n                .filter(token -> !token.isEmpty())\n                .withSelectivity(0.99, 0.99, 0.99)\n                .withName("Filter empty words")\n\n                // Attach counter to each word.\n                .map(word -> new Tuple2<>(word.toLowerCase(), 1)).withName("To lower case, add counter")\n\n                // Sum up counters for every word.\n                .reduceByKey(\n                        Tuple2::getField0,\n                        (t1, t2) -> new Tuple2<>(t1.getField0(), t1.getField1() + t2.getField1())\n                )\n                .withCardinalityEstimator(new DefaultCardinalityEstimator(0.9, 1, false, in -> Math.round(0.01 * in[0])))\n                .withName("Add counters")\n\n                // Execute the plan and collect the results.\n                .collect();\n\n        System.out.println(wordcounts);\n    }\n}\n'})}),"\n",(0,i.jsx)(n.h4,{id:"scala-api",children:"Scala API"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-scala",children:'import org.apache.wayang.api._\nimport org.apache.wayang.core.api.{Configuration, WayangContext}\nimport org.apache.wayang.java.Java\nimport org.apache.wayang.spark.Spark\n\nobject WordcountScala {\n  def main(args: Array[String]) {\n\n    // Settings\n    val inputUrl = "file:/tmp.txt"\n\n    // Get a plan builder.\n    val wayangContext = new WayangContext(new Configuration)\n      .withPlugin(Java.basicPlugin)\n      .withPlugin(Spark.basicPlugin)\n    val planBuilder = new PlanBuilder(wayangContext)\n      .withJobName(s"WordCount ($inputUrl)")\n      .withUdfJarsOf(this.getClass)\n\n    val wordcounts = planBuilder\n      // Read the text file.\n      .readTextFile(inputUrl).withName("Load file")\n\n      // Split each line by non-word characters.\n      .flatMap(_.split("\\\\W+"), selectivity = 10).withName("Split words")\n\n      // Filter empty tokens.\n      .filter(_.nonEmpty, selectivity = 0.99).withName("Filter empty words")\n\n      // Attach counter to each word.\n      .map(word => (word.toLowerCase, 1)).withName("To lower case, add counter")\n\n      // Sum up counters for every word.\n      .reduceByKey(_._1, (c1, c2) => (c1._1, c1._2 + c2._2)).withName("Add counters")\n      .withCardinalityEstimator((in: Long) => math.round(in * 0.01))\n\n      // Execute the plan and collect the results.\n      .collect()\n\n    println(wordcounts)\n  }\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"k-means",children:"k-means"}),"\n",(0,i.jsx)(n.p,{children:"Wayang is also capable of iterative processing, which is, e.g., very important for machine learning algorithms, such as k-means."}),"\n",(0,i.jsx)(n.h4,{id:"scala-api-1",children:"Scala API"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-scala",children:'import org.apache.wayang.api._\nimport org.apache.wayang.core.api.{Configuration, WayangContext}\nimport org.apache.wayang.core.function.FunctionDescriptor.ExtendedSerializableFunction\nimport org.apache.wayang.core.function.ExecutionContext\nimport org.apache.wayang.core.optimizer.costs.LoadProfileEstimators\nimport org.apache.wayang.java.Java\nimport org.apache.wayang.spark.Spark\n\nimport scala.util.Random\nimport scala.collection.JavaConversions._\n\nobject kmeans {\n  def main(args: Array[String]) {\n\n    // Settings\n    val inputUrl = "file:/kmeans.txt"\n    val k = 5\n    val iterations = 100\n    val configuration = new Configuration\n\n    // Get a plan builder.\n    val wayangContext = new WayangContext(new Configuration)\n      .withPlugin(Java.basicPlugin)\n      .withPlugin(Spark.basicPlugin)\n    val planBuilder = new PlanBuilder(wayangContext)\n      .withJobName(s"k-means ($inputUrl, k=$k, $iterations iterations)")\n      .withUdfJarsOf(this.getClass)\n\n    case class Point(x: Double, y: Double)\n    case class TaggedPoint(x: Double, y: Double, cluster: Int)\n    case class TaggedPointCounter(x: Double, y: Double, cluster: Int, count: Long) {\n      def add_points(that: TaggedPointCounter) = TaggedPointCounter(this.x + that.x, this.y + that.y, this.cluster, this.count + that.count)\n      def average = TaggedPointCounter(x / count, y / count, cluster, 0)\n    }\n\n    // Read and parse the input file(s).\n    val points = planBuilder\n      .readTextFile(inputUrl).withName("Read file")\n      .map { line =>\n        val fields = line.split(",")\n        Point(fields(0).toDouble, fields(1).toDouble)\n      }.withName("Create points")\n\n\n    // Create initial centroids.\n    val random = new Random\n    val initialCentroids = planBuilder\n      .loadCollection(for (i <- 1 to k) yield TaggedPointCounter(random.nextGaussian(), random.nextGaussian(), i, 0)).withName("Load random centroids")\n\n    // Declare UDF to select centroid for each data point.\n    class SelectNearestCentroid extends ExtendedSerializableFunction[Point, TaggedPointCounter] {\n\n      /** Keeps the broadcasted centroids. */\n      var centroids: Iterable[TaggedPointCounter] = _\n\n      override def open(executionCtx: ExecutionContext) = {\n        centroids = executionCtx.getBroadcast[TaggedPointCounter]("centroids")\n      }\n\n      override def apply(point: Point): TaggedPointCounter = {\n        var minDistance = Double.PositiveInfinity\n        var nearestCentroidId = -1\n        for (centroid <- centroids) {\n          val distance = Math.pow(Math.pow(point.x - centroid.x, 2) + Math.pow(point.y - centroid.y, 2), 0.5)\n          if (distance < minDistance) {\n            minDistance = distance\n            nearestCentroidId = centroid.cluster\n          }\n        }\n        new TaggedPointCounter(point.x, point.y, nearestCentroidId, 1)\n      }\n    }\n\n    // Do the k-means loop.\n    val finalCentroids = initialCentroids.repeat(iterations, { currentCentroids =>\n      points\n        .mapJava(new SelectNearestCentroid,\n          udfLoad = LoadProfileEstimators.createFromSpecification(\n            "my.udf.costfunction.key", configuration\n          ))\n        .withBroadcast(currentCentroids, "centroids").withName("Find nearest centroid")\n        .reduceByKey(_.cluster, _.add_points(_)).withName("Add up points")\n        .withCardinalityEstimator(k)\n        .map(_.average).withName("Average points")\n    }).withName("Loop")\n\n      // Collect the results.\n      .collect()\n\n    println(finalCentroids)\n  }\n}\n'})})]})}function p(e={}){const{wrapper:n}={...(0,t.a)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},1151:(e,n,a)=>{a.d(n,{Z:()=>s,a:()=>r});var i=a(7294);const t={},o=i.createContext(t);function r(e){const n=i.useContext(o);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),i.createElement(o.Provider,{value:n},e.children)}}}]);